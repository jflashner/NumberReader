{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joshua\\Anaconda3\\envs\\SignModel\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.models import load_model\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n"
     ]
    }
   ],
   "source": [
    "SignModel = load_model('signModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'img.jpg'\n",
    "im = cv2.imread(path)\n",
    "cv2.imshow('image',im)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "im_gray = cv2.GaussianBlur(im_gray, (5, 5), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ret, im_th = cv2.threshold(im_gray, 90, 255, cv2.THRESH_BINARY_INV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, ctrs, hier = cv2.findContours(im_th.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(17, 4031, 1, 1), (0, 3988, 17, 44), (0, 3974, 5, 2), (1442, 2661, 153, 432), (960, 2048, 29, 408), (1875, 2025, 193, 331), (811, 2015, 149, 198), (1259, 1330, 199, 318), (2438, 1143, 171, 397), (745, 500, 191, 468), (1595, 473, 214, 410)]\n"
     ]
    }
   ],
   "source": [
    "rects = [cv2.boundingRect(ctr) for ctr in ctrs]\n",
    "print(rects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4031\n",
      "[[255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      "  255 255 255 255 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      "  255 255 255 255 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      "  255 255 255 255 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      "  255 255 255 255 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      "  255 255 255 255 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      "  255 255 255 255 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      "  255 255 255 255 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      "  255 255 255 255 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      "  255 255 255 255 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      "  255 255 255 255 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      "  255 255 255 255 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      "  255 255 255 255 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      "  255 255 255 255 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      "  255 255 255 255 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      "  255 255 255 255 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      "  255 255 255 255 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      "  255 255 255 255 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      "  255 255 255 255 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      "  255 255 255 255 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      "  255 255 255 255 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      "  255 255 255 255 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      "  255 255 255 255 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      "  255 255 255 255 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      "  255 255 255 255 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      "  255 255 255 255 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      "  255 255 255 255 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      "  255 255 255 255 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      "  255 255 255 255 255 255 255 255 255 255]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joshua\\Anaconda3\\envs\\SignModel\\lib\\site-packages\\skimage\\feature\\_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected input_1 to have 4 dimensions, but got array with shape (1, 36)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3f358625b2b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mroi_hog_fd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morientations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpixels_per_cell\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m14\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcells_per_block\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvisualise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroi_hog_fd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSignModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mroi_hog_fd\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'float64'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mnbr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSignModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mroi_hog_fd\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'float64'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mputText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrect\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrect\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFONT_HERSHEY_DUPLEX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\SignModel\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1822\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[0;32m   1823\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1824\u001b[1;33m                                     check_batch_axis=False)\n\u001b[0m\u001b[0;32m   1825\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1826\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\SignModel\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    111\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    114\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking : expected input_1 to have 4 dimensions, but got array with shape (1, 36)"
     ]
    }
   ],
   "source": [
    "for rect in rects:\n",
    "    cv2.rectangle(im, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (0, 255, 0), 3)\n",
    "    leng = int(rect[3] * 1.6)\n",
    "    pt1 = int(rect[1] + rect[3] // 2 - leng // 2)\n",
    "    print(pt1)\n",
    "    pt2 = int(rect[0] + rect[2] // 2 - leng // 2)\n",
    "    roi = im_th[pt1:pt1+leng, pt2:pt2+leng]\n",
    "    roi = cv2.resize(roi, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "    roi = cv2.dilate(roi, (3, 3))\n",
    "    print(roi)\n",
    "    roi_hog_fd = hog(roi, orientations=9, pixels_per_cell=(14, 14), cells_per_block=(1, 1), visualise=False)\n",
    "    print(roi_hog_fd)\n",
    "    print(SignModel.predict(np.array([roi_hog_fd], 'float64')))\n",
    "    nbr = SignModel.predict(np.array([roi_hog_fd], 'float64'))\n",
    "    cv2.putText(im, str(int(nbr[0])), (rect[0], rect[1]),cv2.FONT_HERSHEY_DUPLEX, 2, (0, 255, 255), 3)\n",
    "\n",
    "cv2.imshow(\"Resulting Image with Rectangular ROIs\", im)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4032, 3024, 3)\n",
      "[(1442, 2661, 153, 432), (960, 2048, 29, 408), (1875, 2025, 193, 331), (811, 2015, 149, 198), (1259, 1330, 199, 318), (2438, 1143, 171, 397), (2449, 1151, 149, 201), (745, 500, 191, 468), (1595, 473, 214, 410)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def overlap(x1,y1,w1,h1,x2,y2,w2,h2):\n",
    "    if x1 < x2 and x1+w1 > x2 and y1 < y2 and y1+h1 > y2:\n",
    "        return True\n",
    "    elif x1 > x2 and x1 < x2+w2 and x2+w2 < x1+x2 and y1 < y2 and y1+h1 > y2:\n",
    "        return True\n",
    "    elif x1 < x2 and x1+w1 > x2 and y1 > y2 and y1 < y2+h2 and y2+h2 < y1+h1:\n",
    "        return True\n",
    "    elif x1 > x2 and x1 < x2+w2 and x2+w2 < x1+w1 and y1 > y2 and y1 < y2+h2 and y2+h2 < y1+h1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "im = cv2.imread('img.jpg')\n",
    "print(im.shape) #check if the image is loaded correctly\n",
    "imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "imgray = cv2.GaussianBlur(imgray, (5, 5), 0)\n",
    "ret,thresh = cv2.threshold(imgray,90,255,cv2.THRESH_BINARY_INV)\n",
    "_,contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "rectlist = []\n",
    "for cont in contours:\n",
    "    x,y,w,h = cv2.boundingRect(cont)\n",
    "    if w*h>50*50:\n",
    "        rectlist.append((x,y,w,h)) \n",
    "for i in range(len(rectlist)):\n",
    "    for j in range(len(rectlist[i:])-1):\n",
    "        if overlap(rectlist[i][0],rectlist[i][1],rectlist[i][2],rectlist[i][3],rectlist[i:][j][0],rectlist[i:][j][1],rectlist[i:][j][2],rectlist[i:][j][3]):\n",
    "            if rectlist[i][2]*rectlist[i][3] > rectlist[i:][j][2]*rectlist[i:][j][3]:\n",
    "                del rectlist[i+j]\n",
    "            else:\n",
    "                del rectlist[i]\n",
    "print(rectlist)\n",
    "for rect in rectlist:\n",
    "    crop_img = im[rect[1]:rect[1]+rect[3], rect[0]:rect[0]+rect[2]]\n",
    "    cv2.imshow(\"cropped\", crop_img)\n",
    "    cv2.waitKey(0)\n",
    "                \n",
    "\n",
    "cv2.imshow(\"window title\", im)\n",
    "cv2.waitKey()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.models import load_model\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "import cv2\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from skimage.feature import hog\n",
    "\n",
    "SignModel = load_model('signModel.h5')\n",
    "\n",
    "def overlap(x1, y1, w1, h1, x2, y2, w2, h2):\n",
    "    if x1 < x2 and x1 + w1 > x2 and y1 < y2 and y1 + h1 > y2:\n",
    "        return True\n",
    "    elif x1 > x2 and x1 < x2 + w2 and x2 + w2 < x1 + x2 and y1 < y2 and y1 + h1 > y2:\n",
    "        return True\n",
    "    elif x1 < x2 and x1 + w1 > x2 and y1 > y2 and y1 < y2 + h2 and y2 + h2 < y1 + h1:\n",
    "        return True\n",
    "    elif x1 > x2 and x1 < x2 + w2 and x2 + w2 < x1 + w1 and y1 > y2 and y1 < y2 + h2 and y2 + h2 < y1 + h1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "im = cv2.imread('img.jpg')\n",
    "imgray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "imgray = cv2.GaussianBlur(imgray, (5, 5), 0)\n",
    "cv2.waitKey()\n",
    "ret, thresh = cv2.threshold(imgray, 90, 255, cv2.THRESH_BINARY_INV)\n",
    "im2, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "rectlist = []\n",
    "for cont in contours:\n",
    "    x, y, w, h = cv2.boundingRect(cont)\n",
    "    if w * h > 50 * 50:\n",
    "        rectlist.append((x, y, w, h))\n",
    "\n",
    "temp = list(rectlist)\n",
    "for i in range(len(rectlist)):\n",
    "    for j in range(len(rectlist[i:]) - 1):\n",
    "        if overlap(rectlist[i][0], rectlist[i][1], rectlist[i][2], rectlist[i][3], rectlist[i:][j][0],\n",
    "                   rectlist[i:][j][1], rectlist[i:][j][2], rectlist[i:][j][3]):\n",
    "            if rectlist[i][2] * rectlist[i][3] > rectlist[i:][j][2] * rectlist[i:][j][3]:\n",
    "                temp.remove(rectlist[i + j])\n",
    "            else:\n",
    "                temp.remove(rectlist[i])\n",
    "rectlist = temp\n",
    "for rect in rectlist:\n",
    "    crop_imgOrig = im2[rect[1]:rect[1] + rect[3], rect[0]:rect[0] + rect[2]]\n",
    "    crop_img = cv2.dilate(crop_imgOrig,(150,150),iterations=30)\n",
    "    image = cv2.copyMakeBorder(cv2.resize(crop_img, (16, 16)), 6, 6, 6, 6, cv2.BORDER_CONSTANT)\n",
    "    prediction = SignModel.predict(np.array(image).reshape(-1,28,28,1))\n",
    "    print(np.where(prediction[0]>0.5)[0][0])\n",
    "    cv2.imshow(\"orginal\",im[rect[1]:rect[1] + rect[3], rect[0]:rect[0] + rect[2]])\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
