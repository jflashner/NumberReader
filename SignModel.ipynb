{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joshua\\Anaconda3\\envs\\SignModel\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras import optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joshua\\Anaconda3\\envs\\SignModel\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../SignData/train.csv')\n",
    "labels = train.ix[:,0].values.astype('int32')\n",
    "X_train = train.ix[:,1:].values.astype('float32')\n",
    "X_train = X_train.reshape((X_train.shape[0],28,28))\n",
    "X_test = (pd.read_csv('../SignData/test.csv').values).astype('float32')\n",
    "\n",
    "y_train = np_utils.to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABLCAYAAABgOHyfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27b8015a0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "im1 = 120\n",
    "im2 = 130\n",
    "for i in range(im1, im2):\n",
    "    plt.subplot(3,im2-im1,1+(i-im1))\n",
    "    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.title(np.where(y_train[i] == 1)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)\n",
    "X_test1 = X_test\n",
    "scale = np.max(X_train)\n",
    "X_train /= scale\n",
    "X_test /= scale\n",
    "\n",
    "mean = np.std(X_train)\n",
    "X_train -= mean\n",
    "X_test -= mean\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "nb_classes = y_train.shape[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SignsModel(input_shape):\n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "    print(X_input)\n",
    "    X = (X_input)\n",
    "    X = Conv2D(32, (5,5), strides = (1,1), name='conv0')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(32, (3, 3), strides = (1, 1), name = 'conv2')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Dropout(0.2)(X)\n",
    "    \n",
    "    X = MaxPooling2D((2, 2), name='max_pool')(X)\n",
    "    \n",
    "    X = Conv2D(64, (3, 3), strides = (1, 1), name = 'conv3')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn3')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(64, (3, 3), strides = (1, 1), name = 'conv4')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn4')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Dropout(0.2)(X)\n",
    "    \n",
    "    X = MaxPooling2D((2, 2), name='max_pool2')(X)\n",
    "    \n",
    "    print(X.get_shape())\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1024, activation='relu', name='fc')(X)\n",
    "    X = Dense(512, activation='relu', name='fc2')(X)\n",
    "    X = Dense(256, activation='relu', name='fc3')(X)\n",
    "    X = Dense(10, activation='softmax', name='fc4')(X)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name='SignModel')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_1:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "(?, 3, 3, 64)\n"
     ]
    }
   ],
   "source": [
    "signsModel = SignsModel((28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "signsModel.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/150\n",
      "42000/42000 [==============================] - 20s 466us/step - loss: 0.1253 - acc: 0.9627\n",
      "Epoch 2/150\n",
      "42000/42000 [==============================] - 18s 420us/step - loss: 0.0516 - acc: 0.9855\n",
      "Epoch 3/150\n",
      "42000/42000 [==============================] - 18s 426us/step - loss: 0.0344 - acc: 0.9900\n",
      "Epoch 4/150\n",
      "42000/42000 [==============================] - 18s 417us/step - loss: 0.0299 - acc: 0.9909\n",
      "Epoch 5/150\n",
      "42000/42000 [==============================] - 18s 417us/step - loss: 0.0234 - acc: 0.9923\n",
      "Epoch 6/150\n",
      "42000/42000 [==============================] - 17s 416us/step - loss: 0.0192 - acc: 0.9939\n",
      "Epoch 7/150\n",
      "42000/42000 [==============================] - 18s 418us/step - loss: 0.0167 - acc: 0.9948\n",
      "Epoch 8/150\n",
      "42000/42000 [==============================] - 17s 417us/step - loss: 0.0152 - acc: 0.9953\n",
      "Epoch 9/150\n",
      "42000/42000 [==============================] - 17s 415us/step - loss: 0.0114 - acc: 0.9967\n",
      "Epoch 10/150\n",
      "42000/42000 [==============================] - 18s 421us/step - loss: 0.0116 - acc: 0.9960\n",
      "Epoch 11/150\n",
      "42000/42000 [==============================] - 17s 414us/step - loss: 0.0108 - acc: 0.9967\n",
      "Epoch 12/150\n",
      "42000/42000 [==============================] - 17s 411us/step - loss: 0.0103 - acc: 0.9966\n",
      "Epoch 13/150\n",
      "42000/42000 [==============================] - 17s 411us/step - loss: 0.0083 - acc: 0.9973\n",
      "Epoch 14/150\n",
      "42000/42000 [==============================] - 17s 411us/step - loss: 0.0079 - acc: 0.9971\n",
      "Epoch 15/150\n",
      "42000/42000 [==============================] - 17s 404us/step - loss: 0.0062 - acc: 0.9981\n",
      "Epoch 16/150\n",
      "42000/42000 [==============================] - 17s 404us/step - loss: 0.0064 - acc: 0.9980\n",
      "Epoch 17/150\n",
      "42000/42000 [==============================] - 17s 405us/step - loss: 0.0062 - acc: 0.9981\n",
      "Epoch 18/150\n",
      "42000/42000 [==============================] - 17s 405us/step - loss: 0.0043 - acc: 0.9987\n",
      "Epoch 19/150\n",
      "42000/42000 [==============================] - 17s 405us/step - loss: 0.0033 - acc: 0.9989\n",
      "Epoch 20/150\n",
      "42000/42000 [==============================] - 17s 412us/step - loss: 0.0057 - acc: 0.9983\n",
      "Epoch 21/150\n",
      "42000/42000 [==============================] - 17s 416us/step - loss: 0.0067 - acc: 0.9975\n",
      "Epoch 22/150\n",
      "42000/42000 [==============================] - 17s 411us/step - loss: 0.0044 - acc: 0.9986\n",
      "Epoch 23/150\n",
      "42000/42000 [==============================] - 17s 412us/step - loss: 0.0042 - acc: 0.9986\n",
      "Epoch 24/150\n",
      "42000/42000 [==============================] - 17s 410us/step - loss: 0.0035 - acc: 0.9989\n",
      "Epoch 25/150\n",
      "42000/42000 [==============================] - 17s 411us/step - loss: 0.0030 - acc: 0.9991\n",
      "Epoch 26/150\n",
      "42000/42000 [==============================] - 17s 411us/step - loss: 0.0045 - acc: 0.9985\n",
      "Epoch 27/150\n",
      "42000/42000 [==============================] - 17s 410us/step - loss: 0.0025 - acc: 0.9991\n",
      "Epoch 28/150\n",
      "42000/42000 [==============================] - 17s 407us/step - loss: 0.0026 - acc: 0.9991\n",
      "Epoch 29/150\n",
      "42000/42000 [==============================] - 17s 405us/step - loss: 0.0036 - acc: 0.9990\n",
      "Epoch 30/150\n",
      "42000/42000 [==============================] - 17s 404us/step - loss: 0.0045 - acc: 0.9985\n",
      "Epoch 31/150\n",
      "42000/42000 [==============================] - 17s 404us/step - loss: 0.0026 - acc: 0.9991\n",
      "Epoch 32/150\n",
      "42000/42000 [==============================] - 17s 401us/step - loss: 0.0026 - acc: 0.9991\n",
      "Epoch 33/150\n",
      "42000/42000 [==============================] - 17s 402us/step - loss: 0.0028 - acc: 0.9993\n",
      "Epoch 34/150\n",
      "42000/42000 [==============================] - 17s 397us/step - loss: 0.0027 - acc: 0.9991\n",
      "Epoch 35/150\n",
      "42000/42000 [==============================] - 17s 397us/step - loss: 0.0021 - acc: 0.9992\n",
      "Epoch 36/150\n",
      "42000/42000 [==============================] - 17s 401us/step - loss: 0.0021 - acc: 0.9994\n",
      "Epoch 37/150\n",
      "42000/42000 [==============================] - 17s 398us/step - loss: 0.0029 - acc: 0.9991\n",
      "Epoch 38/150\n",
      "42000/42000 [==============================] - 17s 402us/step - loss: 0.0020 - acc: 0.9993\n",
      "Epoch 39/150\n",
      "42000/42000 [==============================] - 17s 402us/step - loss: 0.0022 - acc: 0.9994\n",
      "Epoch 40/150\n",
      "42000/42000 [==============================] - 17s 401us/step - loss: 0.0013 - acc: 0.9995\n",
      "Epoch 41/150\n",
      "42000/42000 [==============================] - 17s 402us/step - loss: 0.0015 - acc: 0.9996\n",
      "Epoch 42/150\n",
      "42000/42000 [==============================] - 17s 402us/step - loss: 0.0035 - acc: 0.9991\n",
      "Epoch 43/150\n",
      "42000/42000 [==============================] - 18s 424us/step - loss: 0.0011 - acc: 0.9996\n",
      "Epoch 44/150\n",
      "42000/42000 [==============================] - 17s 416us/step - loss: 0.0016 - acc: 0.9995\n",
      "Epoch 45/150\n",
      "42000/42000 [==============================] - 18s 417us/step - loss: 8.9217e-04 - acc: 0.9998\n",
      "Epoch 46/150\n",
      "42000/42000 [==============================] - 17s 410us/step - loss: 2.6423e-04 - acc: 1.0000\n",
      "Epoch 47/150\n",
      "42000/42000 [==============================] - 18s 424us/step - loss: 3.8971e-04 - acc: 0.9999\n",
      "Epoch 48/150\n",
      "42000/42000 [==============================] - 17s 415us/step - loss: 0.0012 - acc: 0.9997\n",
      "Epoch 49/150\n",
      "42000/42000 [==============================] - 18s 427us/step - loss: 5.6344e-04 - acc: 0.9999\n",
      "Epoch 50/150\n",
      "42000/42000 [==============================] - 18s 424us/step - loss: 5.2199e-04 - acc: 0.9999\n",
      "Epoch 51/150\n",
      "42000/42000 [==============================] - 17s 415us/step - loss: 0.0012 - acc: 0.9996\n",
      "Epoch 52/150\n",
      "42000/42000 [==============================] - 17s 413us/step - loss: 0.0016 - acc: 0.9996\n",
      "Epoch 53/150\n",
      "42000/42000 [==============================] - 17s 407us/step - loss: 6.0761e-04 - acc: 0.9997\n",
      "Epoch 54/150\n",
      "42000/42000 [==============================] - 17s 399us/step - loss: 8.1754e-04 - acc: 0.9997\n",
      "Epoch 55/150\n",
      "42000/42000 [==============================] - 18s 429us/step - loss: 0.0014 - acc: 0.9996\n",
      "Epoch 56/150\n",
      "42000/42000 [==============================] - 17s 413us/step - loss: 2.2831e-04 - acc: 1.0000\n",
      "Epoch 57/150\n",
      "42000/42000 [==============================] - 17s 412us/step - loss: 2.8570e-04 - acc: 0.9999\n",
      "Epoch 58/150\n",
      "42000/42000 [==============================] - 17s 409us/step - loss: 8.4476e-04 - acc: 0.9998\n",
      "Epoch 59/150\n",
      "42000/42000 [==============================] - 17s 405us/step - loss: 8.9307e-04 - acc: 0.9998\n",
      "Epoch 60/150\n",
      "42000/42000 [==============================] - 17s 400us/step - loss: 1.8927e-04 - acc: 1.0000\n",
      "Epoch 61/150\n",
      "42000/42000 [==============================] - 17s 415us/step - loss: 8.3112e-04 - acc: 0.9997\n",
      "Epoch 62/150\n",
      "42000/42000 [==============================] - 17s 415us/step - loss: 6.7005e-04 - acc: 0.9998\n",
      "Epoch 63/150\n",
      "42000/42000 [==============================] - 17s 416us/step - loss: 4.9354e-04 - acc: 0.9998\n",
      "Epoch 64/150\n",
      "42000/42000 [==============================] - 18s 419us/step - loss: 4.4690e-04 - acc: 0.9999\n",
      "Epoch 65/150\n",
      "42000/42000 [==============================] - 18s 423us/step - loss: 3.1010e-04 - acc: 1.0000\n",
      "Epoch 66/150\n",
      "42000/42000 [==============================] - 18s 420us/step - loss: 4.7219e-04 - acc: 1.0000\n",
      "Epoch 67/150\n",
      "42000/42000 [==============================] - 18s 417us/step - loss: 1.8981e-04 - acc: 1.0000\n",
      "Epoch 68/150\n",
      "42000/42000 [==============================] - 18s 422us/step - loss: 5.2282e-04 - acc: 0.9999\n",
      "Epoch 69/150\n",
      "42000/42000 [==============================] - 17s 414us/step - loss: 1.6742e-04 - acc: 1.0000\n",
      "Epoch 70/150\n",
      "42000/42000 [==============================] - 17s 412us/step - loss: 1.4482e-04 - acc: 1.0000\n",
      "Epoch 71/150\n",
      "42000/42000 [==============================] - 17s 409us/step - loss: 0.0013 - acc: 0.9997\n",
      "Epoch 72/150\n",
      "42000/42000 [==============================] - 17s 415us/step - loss: 9.8260e-04 - acc: 0.9996\n",
      "Epoch 73/150\n",
      "42000/42000 [==============================] - 17s 416us/step - loss: 5.7729e-04 - acc: 0.9997\n",
      "Epoch 74/150\n",
      "42000/42000 [==============================] - 18s 420us/step - loss: 0.0014 - acc: 0.9996\n",
      "Epoch 75/150\n",
      "42000/42000 [==============================] - 18s 425us/step - loss: 0.0014 - acc: 0.9995\n",
      "Epoch 76/150\n",
      "42000/42000 [==============================] - 18s 429us/step - loss: 3.8784e-04 - acc: 0.9999\n",
      "Epoch 77/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000/42000 [==============================] - 18s 420us/step - loss: 8.3954e-04 - acc: 0.9998\n",
      "Epoch 78/150\n",
      "42000/42000 [==============================] - 18s 420us/step - loss: 1.8529e-04 - acc: 1.0000\n",
      "Epoch 79/150\n",
      "42000/42000 [==============================] - 17s 415us/step - loss: 3.4330e-04 - acc: 0.9999\n",
      "Epoch 80/150\n",
      "42000/42000 [==============================] - 18s 421us/step - loss: 3.5682e-04 - acc: 1.0000\n",
      "Epoch 81/150\n",
      "42000/42000 [==============================] - 18s 417us/step - loss: 3.4885e-04 - acc: 0.9999\n",
      "Epoch 82/150\n",
      "42000/42000 [==============================] - 18s 424us/step - loss: 1.6917e-04 - acc: 1.0000\n",
      "Epoch 83/150\n",
      "42000/42000 [==============================] - 18s 419us/step - loss: 1.5045e-04 - acc: 1.0000\n",
      "Epoch 84/150\n",
      "42000/42000 [==============================] - 18s 417us/step - loss: 7.9459e-05 - acc: 1.0000\n",
      "Epoch 85/150\n",
      "42000/42000 [==============================] - 17s 415us/step - loss: 5.2571e-05 - acc: 1.0000\n",
      "Epoch 86/150\n",
      "42000/42000 [==============================] - 18s 421us/step - loss: 7.8144e-04 - acc: 0.9998\n",
      "Epoch 87/150\n",
      "42000/42000 [==============================] - 18s 420us/step - loss: 1.4949e-04 - acc: 1.0000\n",
      "Epoch 88/150\n",
      "42000/42000 [==============================] - 17s 414us/step - loss: 5.5384e-05 - acc: 1.0000\n",
      "Epoch 89/150\n",
      "42000/42000 [==============================] - 17s 414us/step - loss: 1.5977e-04 - acc: 1.0000\n",
      "Epoch 90/150\n",
      "42000/42000 [==============================] - 17s 417us/step - loss: 4.7325e-05 - acc: 1.0000\n",
      "Epoch 91/150\n",
      "42000/42000 [==============================] - 17s 416us/step - loss: 3.0667e-04 - acc: 1.0000\n",
      "Epoch 92/150\n",
      "42000/42000 [==============================] - 18s 419us/step - loss: 7.2425e-04 - acc: 0.9998\n",
      "Epoch 93/150\n",
      "42000/42000 [==============================] - 18s 419us/step - loss: 1.0768e-04 - acc: 1.0000\n",
      "Epoch 94/150\n",
      "42000/42000 [==============================] - 18s 419us/step - loss: 3.7364e-05 - acc: 1.0000\n",
      "Epoch 95/150\n",
      "42000/42000 [==============================] - 17s 414us/step - loss: 3.5875e-05 - acc: 1.0000\n",
      "Epoch 96/150\n",
      "42000/42000 [==============================] - 17s 413us/step - loss: 2.0489e-04 - acc: 0.9999\n",
      "Epoch 97/150\n",
      "42000/42000 [==============================] - 18s 418us/step - loss: 8.1289e-04 - acc: 0.9999\n",
      "Epoch 98/150\n",
      "42000/42000 [==============================] - 18s 418us/step - loss: 2.1388e-04 - acc: 0.9999\n",
      "Epoch 99/150\n",
      "42000/42000 [==============================] - 17s 416us/step - loss: 0.0016 - acc: 0.9997\n",
      "Epoch 100/150\n",
      "42000/42000 [==============================] - 17s 412us/step - loss: 0.0013 - acc: 0.9995\n",
      "Epoch 101/150\n",
      "42000/42000 [==============================] - 17s 417us/step - loss: 5.5906e-04 - acc: 0.9998\n",
      "Epoch 102/150\n",
      "42000/42000 [==============================] - 17s 414us/step - loss: 4.5311e-04 - acc: 0.9998\n",
      "Epoch 103/150\n",
      "42000/42000 [==============================] - 17s 415us/step - loss: 4.3743e-04 - acc: 0.9999\n",
      "Epoch 104/150\n",
      "42000/42000 [==============================] - 17s 416us/step - loss: 5.0951e-04 - acc: 0.9999\n",
      "Epoch 105/150\n",
      "42000/42000 [==============================] - 17s 412us/step - loss: 7.0557e-05 - acc: 1.0000\n",
      "Epoch 106/150\n",
      "42000/42000 [==============================] - 17s 416us/step - loss: 5.4548e-04 - acc: 0.9998\n",
      "Epoch 107/150\n",
      "42000/42000 [==============================] - 17s 413us/step - loss: 0.0011 - acc: 0.9996\n",
      "Epoch 108/150\n",
      "42000/42000 [==============================] - 17s 414us/step - loss: 6.1139e-04 - acc: 0.9998\n",
      "Epoch 109/150\n",
      "42000/42000 [==============================] - ETA: 0s - loss: 3.6872e-04 - acc: 0.999 - 17s 414us/step - loss: 3.6789e-04 - acc: 0.9998\n",
      "Epoch 110/150\n",
      "42000/42000 [==============================] - 17s 417us/step - loss: 1.8637e-04 - acc: 1.0000\n",
      "Epoch 111/150\n",
      "42000/42000 [==============================] - 17s 410us/step - loss: 5.4110e-04 - acc: 0.9999\n",
      "Epoch 112/150\n",
      "42000/42000 [==============================] - 17s 414us/step - loss: 6.8010e-05 - acc: 1.0000\n",
      "Epoch 113/150\n",
      "42000/42000 [==============================] - 18s 421us/step - loss: 4.7753e-05 - acc: 1.0000\n",
      "Epoch 114/150\n",
      "42000/42000 [==============================] - 18s 424us/step - loss: 2.5357e-05 - acc: 1.0000\n",
      "Epoch 115/150\n",
      "42000/42000 [==============================] - 18s 430us/step - loss: 6.5149e-05 - acc: 1.0000\n",
      "Epoch 116/150\n",
      "42000/42000 [==============================] - 18s 419us/step - loss: 2.2054e-05 - acc: 1.0000\n",
      "Epoch 117/150\n",
      "42000/42000 [==============================] - 18s 418us/step - loss: 1.9640e-05 - acc: 1.0000\n",
      "Epoch 118/150\n",
      "42000/42000 [==============================] - 18s 420us/step - loss: 1.7900e-05 - acc: 1.0000\n",
      "Epoch 119/150\n",
      "42000/42000 [==============================] - 18s 422us/step - loss: 3.0843e-05 - acc: 1.0000\n",
      "Epoch 120/150\n",
      "42000/42000 [==============================] - 18s 418us/step - loss: 2.8055e-04 - acc: 0.9999\n",
      "Epoch 121/150\n",
      "42000/42000 [==============================] - 18s 418us/step - loss: 6.1387e-05 - acc: 1.0000\n",
      "Epoch 122/150\n",
      "42000/42000 [==============================] - 18s 417us/step - loss: 1.4667e-05 - acc: 1.0000\n",
      "Epoch 123/150\n",
      "42000/42000 [==============================] - 17s 416us/step - loss: 3.6372e-05 - acc: 1.0000\n",
      "Epoch 124/150\n",
      "42000/42000 [==============================] - 18s 417us/step - loss: 1.9532e-05 - acc: 1.0000\n",
      "Epoch 125/150\n",
      "42000/42000 [==============================] - 17s 415us/step - loss: 1.4313e-05 - acc: 1.0000\n",
      "Epoch 126/150\n",
      "42000/42000 [==============================] - 18s 419us/step - loss: 2.3785e-05 - acc: 1.0000\n",
      "Epoch 127/150\n",
      "42000/42000 [==============================] - 18s 420us/step - loss: 1.4652e-05 - acc: 1.0000\n",
      "Epoch 128/150\n",
      "42000/42000 [==============================] - 18s 421us/step - loss: 3.1341e-05 - acc: 1.0000\n",
      "Epoch 129/150\n",
      "42000/42000 [==============================] - 18s 428us/step - loss: 0.0012 - acc: 0.9995\n",
      "Epoch 130/150\n",
      "42000/42000 [==============================] - 18s 431us/step - loss: 8.4570e-04 - acc: 0.9998\n",
      "Epoch 131/150\n",
      "42000/42000 [==============================] - 18s 423us/step - loss: 6.1409e-04 - acc: 0.9998\n",
      "Epoch 132/150\n",
      "42000/42000 [==============================] - 18s 420us/step - loss: 9.2187e-05 - acc: 1.0000\n",
      "Epoch 133/150\n",
      "42000/42000 [==============================] - 18s 421us/step - loss: 3.1253e-05 - acc: 1.0000\n",
      "Epoch 134/150\n",
      "42000/42000 [==============================] - 18s 420us/step - loss: 3.8099e-05 - acc: 1.0000\n",
      "Epoch 135/150\n",
      "42000/42000 [==============================] - 18s 420us/step - loss: 3.3908e-05 - acc: 1.0000\n",
      "Epoch 136/150\n",
      "42000/42000 [==============================] - 18s 420us/step - loss: 2.0262e-04 - acc: 0.9999\n",
      "Epoch 137/150\n",
      "42000/42000 [==============================] - 18s 431us/step - loss: 3.4868e-05 - acc: 1.0000\n",
      "Epoch 138/150\n",
      "42000/42000 [==============================] - 18s 427us/step - loss: 3.1744e-05 - acc: 1.0000\n",
      "Epoch 139/150\n",
      "42000/42000 [==============================] - 18s 424us/step - loss: 1.3553e-05 - acc: 1.0000\n",
      "Epoch 140/150\n",
      "42000/42000 [==============================] - 19s 444us/step - loss: 4.6942e-05 - acc: 1.0000\n",
      "Epoch 141/150\n",
      "42000/42000 [==============================] - 19s 446us/step - loss: 3.3252e-05 - acc: 1.0000\n",
      "Epoch 142/150\n",
      "42000/42000 [==============================] - 19s 443us/step - loss: 1.6452e-05 - acc: 1.0000\n",
      "Epoch 143/150\n",
      "42000/42000 [==============================] - 19s 444us/step - loss: 1.1573e-05 - acc: 1.0000\n",
      "Epoch 144/150\n",
      "42000/42000 [==============================] - 19s 446us/step - loss: 2.3689e-05 - acc: 1.0000\n",
      "Epoch 145/150\n",
      "42000/42000 [==============================] - 19s 445us/step - loss: 6.1766e-05 - acc: 1.0000\n",
      "Epoch 146/150\n",
      "42000/42000 [==============================] - 19s 445us/step - loss: 2.3762e-05 - acc: 1.0000\n",
      "Epoch 147/150\n",
      "42000/42000 [==============================] - 19s 456us/step - loss: 1.2933e-05 - acc: 1.0000\n",
      "Epoch 148/150\n",
      "42000/42000 [==============================] - 19s 442us/step - loss: 8.7864e-06 - acc: 1.0000\n",
      "Epoch 149/150\n",
      "42000/42000 [==============================] - 19s 441us/step - loss: 9.6505e-06 - acc: 1.0000\n",
      "Epoch 150/150\n",
      "42000/42000 [==============================] - 19s 441us/step - loss: 1.6638e-05 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27b80511710>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signsModel.fit(x=X_train, y=y_train, epochs=150,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating test predictions...\n",
      "(28000, 28, 28, 1)\n",
      "[2 0 9 ... 3 9 2]\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'keras-mlp.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-5386defb3fca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"ImageId\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Label\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mwrite_preds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"keras-mlp.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-5386defb3fca>\u001b[0m in \u001b[0;36mwrite_preds\u001b[1;34m(preds, fname)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mwrite_preds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"ImageId\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Label\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mwrite_preds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"keras-mlp.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\SignModel\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   1401\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1402\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 1403\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1405\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\SignModel\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1575\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[0;32m   1576\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1577\u001b[1;33m                                      compression=self.compression)\n\u001b[0m\u001b[0;32m   1578\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\SignModel\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[1;31m# Python 3 and no explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'replace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[1;31m# Python 3 and binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'keras-mlp.csv'"
     ]
    }
   ],
   "source": [
    "print(\"Generating test predictions...\")\n",
    "print(X_test.shape)\n",
    "preds = np.argmax(signsModel.predict(X_test,batch_size=16, verbose=0),axis=1)\n",
    "print(preds)\n",
    "def write_preds(preds, fname):\n",
    "    pd.DataFrame({\"ImageId\": list(range(1,len(preds)+1)), \"Label\": preds}).to_csv(fname, index=False, header=True)\n",
    "\n",
    "write_preds(preds, \"keras-mlp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "signsModel.save('signModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
